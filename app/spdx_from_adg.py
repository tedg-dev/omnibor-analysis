#!/usr/bin/env python3
"""
Generate a complete SPDX 2.3 JSON document from OmniBOR ADG data.

Reads the bomsh treedb, doc_mapping, raw logfile, and
component_metadata.json (produced by collect_metadata.py) to
build an SPDX SBOM that accurately represents every component
compiled into the target binary.

Each upstream source package (e.g. openssl, zlib, brotli) becomes
an SPDX Package with:
  - name, version, supplier, homepage
  - PURL (pkg:deb/ubuntu/...)
  - CPE 2.3 identifier
  - OmniBOR ExternalRef (gitoid) where available
  - DEPENDS_ON relationship from the main binary package

The target binary itself is the root package with its OmniBOR
ExternalRef and a CONTAINS relationship to its source files.

Usage (standalone):

    python3 spdx_from_adg.py \\
        --bom-dir /output/omnibor/curl \\
        --repos-dir /workspace/repos \\
        --repo-name curl \\
        --output /output/spdx/curl/curl_adg.spdx.json

Classes:

    - AdgParser: reads treedb and classifies artifacts
    - ComponentResolver: maps artifacts to named components
    - SpdxEmitter: produces SPDX 2.3 JSON from resolved data
    - AdgSpdxGenerator: facade orchestrating the pipeline
"""

import argparse
import json
import re
import uuid
from datetime import datetime, timezone
from pathlib import Path


# ============================================================
# ADG Parser
# ============================================================

class AdgParser:
    """Parse bomsh treedb and classify artifacts.

    Artifact categories:
      - system_lib: shared libraries under /usr/lib
      - system_header: headers under /usr/include
      - project_source: files under the project repo
      - build_intermediate: .o files under the project repo
      - crt_object: C runtime objects (crt*.o)
    """

    def __init__(self, bom_dir, repos_dir):
        self.bom_dir = Path(bom_dir)
        self.repos_dir = Path(repos_dir)
        self.meta_dir = (
            self.bom_dir / "metadata" / "bomsh"
        )

    def parse(self):
        """Return classified artifacts dict.

        Keys: system_lib, system_header,
              project_source, build_intermediate,
              crt_object.
        Each value is a list of dicts with keys:
          sha1, file_path, build_cmd (if present).
        """
        treedb_path = (
            self.meta_dir / "bomsh_omnibor_treedb"
        )
        treedb = json.loads(treedb_path.read_text())

        classified = {
            "system_lib": [],
            "system_header": [],
            "project_source": [],
            "build_intermediate": [],
            "crt_object": [],
        }

        for sha1, entry in treedb.items():
            fp = entry.get("file_path", "")
            if not fp:
                continue

            item = {
                "sha1": sha1,
                "file_path": fp,
            }
            if "build_cmd" in entry:
                item["build_cmd"] = entry["build_cmd"]

            if fp.startswith("/usr/lib"):
                base = Path(fp).name
                if base.startswith("crt") and (
                    base.endswith(".o")
                ):
                    classified["crt_object"].append(
                        item
                    )
                elif base.endswith(".so") or (
                    ".so." in base
                ):
                    classified["system_lib"].append(
                        item
                    )
                else:
                    # Static libs, other objects
                    classified["system_lib"].append(
                        item
                    )
            elif fp.startswith("/usr/include"):
                classified["system_header"].append(
                    item
                )
            elif fp.startswith(str(self.repos_dir)):
                if fp.endswith(".o"):
                    classified[
                        "build_intermediate"
                    ].append(item)
                else:
                    classified[
                        "project_source"
                    ].append(item)
            else:
                # Other system files
                classified["system_header"].append(
                    item
                )

        return classified

    def load_doc_mapping(self):
        """Return dict: sha1 -> omnibor_doc_id."""
        path = (
            self.meta_dir / "bomsh_omnibor_doc_mapping"
        )
        if not path.exists():
            return {}
        return json.loads(path.read_text())

    def load_raw_logfile_hashes(self):
        """Return dict: file_path -> build-time sha1."""
        path = (
            self.meta_dir / "bomsh_hook_raw_logfile"
        )
        if not path.exists():
            return {}
        result = {}
        for line in path.read_text(
            errors="replace"
        ).splitlines():
            m = re.match(
                r"^outfile:\s+([0-9a-f]{40})"
                r"\s+path:\s+(.+)$",
                line,
            )
            if m:
                result[m.group(2)] = m.group(1)
        return result


# ============================================================
# Component Resolver
# ============================================================

class ComponentResolver:
    """Resolve artifacts to named software components.

    Uses component_metadata.json (from collect_metadata.py)
    and dynamic_libs.json (from collect_dynamic_libs.py)
    to identify runtime dependencies with full metadata.
    """

    def __init__(self, metadata_path):
        self.metadata = json.loads(
            Path(metadata_path).read_text()
        )
        self._dynamic_libs = None

    @property
    def distro(self):
        return self.metadata.get("distro", "unknown")

    @property
    def distro_codename(self):
        """Extract distro version for PURL qualifier."""
        d = self.distro.lower()
        # "Ubuntu 22.04.5 LTS" -> "ubuntu-22.04"
        m = re.search(r"ubuntu\s+([\d.]+)", d)
        if m:
            # Use major.minor only
            parts = m.group(1).split(".")
            ver = ".".join(parts[:2])
            return f"ubuntu-{ver}"
        return "linux"

    @property
    def gcc_version(self):
        return self.metadata.get(
            "gcc_version", "unknown"
        )

    @property
    def curl_version(self):
        return self.metadata.get(
            "curl_version", "unknown"
        )

    def load_dynamic_libs(self, path):
        """Load dynamic_libs.json."""
        self._dynamic_libs = json.loads(
            Path(path).read_text()
        )

    def resolve_dynamic_components(self):
        """Resolve dynamic libraries to components.

        Groups libraries by upstream source package.
        Each component has:
          name, version, supplier, homepage,
          dpkg_packages, architecture, purl, cpe23,
          sonames, direct (bool).
        """
        if not self._dynamic_libs:
            return []

        libs = self._dynamic_libs.get(
            "dynamic_libs", {}
        )

        # Group by upstream source
        source_groups = {}
        for soname, info in libs.items():
            meta = info.get("metadata", {})
            source = info.get("source", soname)
            if not meta.get("Version"):
                continue
            if source not in source_groups:
                source_groups[source] = {
                    "meta": meta,
                    "sonames": [],
                    "direct": False,
                    "dpkg_packages": set(),
                }
            source_groups[source][
                "sonames"
            ].append(soname)
            if info.get("direct"):
                source_groups[source][
                    "direct"
                ] = True
            dpkg = info.get("dpkg_package")
            if dpkg:
                source_groups[source][
                    "dpkg_packages"
                ].add(dpkg)

        components = []
        for source, group in sorted(
            source_groups.items()
        ):
            meta = group["meta"]
            version = meta.get("Version", "unknown")
            arch = meta.get(
                "Architecture", "amd64"
            )
            dpkg_pkgs = sorted(
                group["dpkg_packages"]
            )
            dpkg_pkg = (
                dpkg_pkgs[0] if dpkg_pkgs
                else source
            )
            cpe_ver = self._clean_version(version)

            comp = {
                "name": source,
                "version": version,
                "supplier": meta.get(
                    "Maintainer", "NOASSERTION"
                ),
                "homepage": meta.get(
                    "Homepage", "NOASSERTION"
                ),
                "dpkg_packages": dpkg_pkgs,
                "architecture": arch,
                "purl": self._make_purl(
                    dpkg_pkg, version, arch
                ),
                "cpe23": self._make_cpe(
                    source, cpe_ver
                ),
                "sonames": sorted(
                    group["sonames"]
                ),
                "direct": group["direct"],
            }
            components.append(comp)

        return components

    def _clean_version(self, version):
        """Strip epoch, dfsg, ubuntu suffixes for CPE."""
        v = version
        # Remove epoch (e.g. "1:1.2.11...")
        if ":" in v:
            v = v.split(":", 1)[1]
        # Remove dfsg suffix
        v = re.sub(r"[.+]dfsg.*", "", v)
        # Remove ubuntu/build suffix
        v = re.sub(r"-\d+ubuntu.*", "", v)
        v = re.sub(r"-\d+build.*", "", v)
        v = re.sub(r"-\d+$", "", v)
        return v

    def _make_purl(self, dpkg_pkg, version, arch):
        """Generate Package URL."""
        distro = self.distro_codename
        return (
            f"pkg:deb/ubuntu/{dpkg_pkg}"
            f"@{version}"
            f"?arch={arch}&distro={distro}"
        )

    def _make_cpe(self, source, version):
        """Generate CPE 2.3 identifier."""
        # Normalize vendor: use source name as vendor
        vendor = source.replace("-", "_")
        product = source.replace("-", "_")
        return (
            f"cpe:2.3:a:{vendor}:{product}"
            f":{version}:*:*:*:*:*:*:*"
        )


# ============================================================
# SPDX Emitter
# ============================================================

class SpdxEmitter:
    """Produce SPDX 2.3 JSON from resolved components.

    Generates a complete SPDX document with:
      - Document-level metadata (namespace, creators)
      - Root package for the target binary
      - One package per dynamically linked library
        (primaryPackagePurpose: LIBRARY)
      - ExternalRefs: PURL, CPE, OmniBOR gitoid
      - Relationships: DYNAMIC_LINK, BUILD_TOOL_OF
      - File entries for project source files
    """

    NAMESPACE_PREFIX = (
        "https://omnibor.io/omnibor-analysis"
    )

    def __init__(
        self, repo_name, repo_version,
        distro, gcc_version,
        bomtrace_version="unknown",
        bomsh_version="unknown",
        binary_name=None,
    ):
        self.repo_name = repo_name
        self.repo_version = repo_version
        self.distro = distro
        self.gcc_version = gcc_version
        self.bomtrace_version = bomtrace_version
        self.bomsh_version = bomsh_version
        self.binary_name = (
            binary_name or repo_name
        )
        self._spdx_id_counter = 0

    def _next_spdx_id(self, prefix="Package"):
        """Generate unique SPDX identifier."""
        self._spdx_id_counter += 1
        return (
            f"SPDXRef-{prefix}"
            f"-{self._spdx_id_counter}"
        )

    def _sanitize_spdx_id(self, name):
        """Sanitize a name for use in SPDX IDs."""
        return re.sub(r"[^a-zA-Z0-9._-]", "-", name)

    # Directories that indicate vendored/embedded
    # third-party source code.
    VENDORED_DIRS = (
        "/deps/", "/vendor/", "/third_party/",
        "/thirdparty/", "/external/", "/contrib/",
    )

    def _detect_vendored_groups(self, project_files):
        """Group source files by vendored library.

        Scans project_files for paths matching
        VENDORED_DIRS patterns. Returns:
          vendored: dict[lib_name] -> list[artifact]
          own: list[artifact]  (non-vendored)
        """
        vendored = {}
        own = []
        for art in project_files:
            fp = art["file_path"]
            matched = False
            for vdir in self.VENDORED_DIRS:
                idx = fp.find(vdir)
                if idx < 0:
                    continue
                # Extract library name: first path
                # component after the vendored dir
                rest = fp[idx + len(vdir):]
                lib = rest.split("/")[0]
                if lib:
                    vendored.setdefault(
                        lib, []
                    ).append(art)
                    matched = True
                    break
            if not matched:
                own.append(art)
        return vendored, own

    def emit(
        self, components, project_files,
        doc_mapping, logfile_hashes,
        direct_only=False,
    ):
        """Generate SPDX 2.3 JSON dict.

        Args:
            components: list of resolved component dicts
            project_files: list of project source artifacts
            doc_mapping: sha1 -> omnibor_doc_id
            logfile_hashes: file_path -> build-time sha1
            direct_only: if True, include only direct
                dependencies (exclude transitive).
                Use for two-tier SBOMs where transitive
                deps belong to a downstream SBOM.

        Returns:
            dict: complete SPDX 2.3 JSON document
        """
        doc_uuid = str(uuid.uuid4())
        now = datetime.now(timezone.utc).strftime(
            "%Y-%m-%dT%H:%M:%SZ"
        )

        doc = {
            "spdxVersion": "SPDX-2.3",
            "dataLicense": "CC0-1.0",
            "SPDXID": "SPDXRef-DOCUMENT",
            "name": self.binary_name,
            "documentNamespace": (
                f"{self.NAMESPACE_PREFIX}"
                f"/{self.binary_name}-{doc_uuid}"
            ),
            "creationInfo": {
                "created": now,
                "creators": [
                    f"Tool: bomtrace3"
                    f"-{self.bomtrace_version}",
                    f"Tool: bomsh"
                    f"-{self.bomsh_version}",
                    "Tool: omnibor-analysis"
                    " (github.com/tedg-dev"
                    "/omnibor-analysis)",
                ],
                "licenseListVersion": "3.19",
            },
            "packages": [],
            "files": [],
            "relationships": [],
        }

        # --- Root package: the target binary ---
        is_shared_lib = (
            self.binary_name.endswith(".so")
            or ".so." in self.binary_name
        )
        root_purpose = (
            "LIBRARY" if is_shared_lib
            else "APPLICATION"
        )
        root_id = "SPDXRef-Package-root"
        root_pkg = {
            "SPDXID": root_id,
            "name": self.binary_name,
            "downloadLocation": "NOASSERTION",
            "filesAnalyzed": True,
            "primaryPackagePurpose": root_purpose,
            "builtDate": now,
            "externalRefs": [],
            "checksums": [],
            "comment": (
                f"Built on {self.distro} with "
                f"{self.gcc_version}"
            ),
        }
        if self.repo_version:
            root_pkg["versionInfo"] = (
                self.repo_version
            )

        # Add OmniBOR ref for root binary
        for bin_path, sha1 in (
            logfile_hashes.items()
        ):
            basename = Path(bin_path).name
            if basename == self.binary_name:
                omnibor_id = doc_mapping.get(sha1)
                if omnibor_id:
                    root_pkg["externalRefs"].append({
                        "referenceCategory":
                            "PERSISTENT-ID",
                        "referenceType": "gitoid",
                        "referenceLocator":
                            f"gitoid:blob:sha1:"
                            f"{omnibor_id}",
                    })
                root_pkg["checksums"].append({
                    "algorithm": "SHA1",
                    "checksumValue": sha1,
                })
                break

        doc["packages"].append(root_pkg)

        # DESCRIBES relationship
        doc["relationships"].append({
            "spdxElementId": "SPDXRef-DOCUMENT",
            "relationshipType": "DESCRIBES",
            "relatedSpdxElement": root_id,
        })

        # --- Dynamic library packages ---
        if direct_only:
            components = [
                c for c in components
                if c.get("direct")
            ]

        for comp in components:
            safe_name = self._sanitize_spdx_id(
                comp["name"]
            )
            pkg_id = self._next_spdx_id(safe_name)

            linkage = (
                "direct" if comp.get("direct")
                else "transitive"
            )
            sonames = comp.get("sonames", [])
            dpkg_pkgs = comp.get(
                "dpkg_packages", []
            )

            dl = (
                comp["homepage"]
                if comp.get("homepage")
                and comp["homepage"]
                != "NOASSERTION"
                else "NOASSERTION"
            )
            pkg = {
                "SPDXID": pkg_id,
                "name": comp["name"],
                "downloadLocation": dl,
                "filesAnalyzed": False,
                "primaryPackagePurpose": "LIBRARY",
                "externalRefs": [],
                "comment": (
                    f"Dynamically linked ({linkage}). "
                    f"sonames: {', '.join(sonames)}. "
                    f"dpkg: "
                    f"{', '.join(dpkg_pkgs)}"
                    f" ({comp.get('architecture', 'amd64')})"
                ),
            }

            # PURL
            if comp.get("purl"):
                pkg["externalRefs"].append({
                    "referenceCategory":
                        "PACKAGE-MANAGER",
                    "referenceType": "purl",
                    "referenceLocator":
                        comp["purl"],
                })

            # CPE
            if comp.get("cpe23"):
                pkg["externalRefs"].append({
                    "referenceCategory":
                        "SECURITY",
                    "referenceType": "cpe23Type",
                    "referenceLocator":
                        comp["cpe23"],
                })

            # Add optional fields only when known
            if comp.get("version"):
                pkg["versionInfo"] = comp["version"]
            supplier = comp.get("supplier", "")
            if (
                supplier
                and supplier != "NOASSERTION"
            ):
                pkg["supplier"] = (
                    f"Organization: {supplier}"
                )
            hp = comp.get("homepage", "")
            if hp and hp != "NOASSERTION":
                pkg["homepage"] = hp

            doc["packages"].append(pkg)

            # DYNAMIC_LINK from root
            doc["relationships"].append({
                "spdxElementId": root_id,
                "relationshipType":
                    "DYNAMIC_LINK",
                "relatedSpdxElement": pkg_id,
            })

        # --- GCC as build tool ---
        gcc_id = self._next_spdx_id("gcc")
        gcc_ver_clean = re.search(
            r"(\d+\.\d+\.\d+)", self.gcc_version
        )
        gcc_ver = (
            gcc_ver_clean.group(1)
            if gcc_ver_clean
            else self.gcc_version
        )
        gcc_pkg = {
            "SPDXID": gcc_id,
            "name": "gcc",
            "versionInfo": gcc_ver,
            "supplier": (
                "Organization: "
                "Free Software Foundation"
            ),
            "downloadLocation": "https://gcc.gnu.org/",
            "homepage": "https://gcc.gnu.org/",
            "filesAnalyzed": False,
            "primaryPackagePurpose": "APPLICATION",
            "externalRefs": [{
                "referenceCategory": "SECURITY",
                "referenceType": "cpe23Type",
                "referenceLocator": (
                    f"cpe:2.3:a:gnu:gcc:{gcc_ver}"
                    f":*:*:*:*:*:*:*"
                ),
            }],
        }
        doc["packages"].append(gcc_pkg)
        doc["relationships"].append({
            "spdxElementId": gcc_id,
            "relationshipType": "BUILD_TOOL_OF",
            "relatedSpdxElement": root_id,
        })

        # --- Vendored (statically linked) packages ---
        vendored, own_files = (
            self._detect_vendored_groups(
                project_files
            )
        )
        # Map vendored lib name -> SPDX package ID
        vendored_pkg_ids = {}
        for lib_name in sorted(vendored.keys()):
            safe_name = self._sanitize_spdx_id(
                lib_name
            )
            pkg_id = self._next_spdx_id(safe_name)
            vendored_pkg_ids[lib_name] = pkg_id

            src_count = len([
                a for a in vendored[lib_name]
                if Path(a["file_path"]).suffix.lower()
                in (".c", ".h", ".s", ".inc",
                    ".cc", ".cpp", ".cxx", ".hpp")
            ])
            pkg = {
                "SPDXID": pkg_id,
                "name": lib_name,
                "downloadLocation": "NOASSERTION",
                "filesAnalyzed": True,
                "primaryPackagePurpose": "LIBRARY",
                "externalRefs": [],
                "comment": (
                    f"Vendored/statically linked. "
                    f"{src_count} source files "
                    f"compiled into {self.binary_name}"
                ),
            }
            doc["packages"].append(pkg)

            # STATIC_LINK from root
            doc["relationships"].append({
                "spdxElementId": root_id,
                "relationshipType":
                    "STATIC_LINK",
                "relatedSpdxElement": pkg_id,
            })

        # --- Project source files ---
        all_source = (
            [(art, None) for art in own_files]
            + [
                (art, lib)
                for lib, arts in vendored.items()
                for art in arts
            ]
        )
        for art, vendored_lib in all_source:
            fp = art["file_path"]
            # Only include .c, .h, .S files
            ext = Path(fp).suffix.lower()
            if ext not in (
                ".c", ".h", ".s", ".inc",
                ".cc", ".cpp", ".cxx", ".hpp",
            ):
                continue

            safe = self._sanitize_spdx_id(
                Path(fp).name
            )
            file_id = self._next_spdx_id(
                f"File-{safe}"
            )
            # Make path relative to repo
            rel_path = fp
            try:
                rel_path = str(
                    Path(fp).relative_to(
                        Path(fp).parents[
                            len(Path(fp).parts) - 3
                        ]
                    )
                )
            except (ValueError, IndexError):
                pass

            file_entry = {
                "SPDXID": file_id,
                "fileName": rel_path,
                "checksums": [{
                    "algorithm": "SHA1",
                    "checksumValue": art["sha1"],
                }],
            }
            doc["files"].append(file_entry)

            # Vendored files belong to their
            # library package; others to root
            owner_id = (
                vendored_pkg_ids[vendored_lib]
                if vendored_lib
                else root_id
            )
            doc["relationships"].append({
                "spdxElementId": owner_id,
                "relationshipType": "CONTAINS",
                "relatedSpdxElement": file_id,
            })

        return doc


# ============================================================
# Facade
# ============================================================

class AdgSpdxGenerator:
    """Facade: generate per-binary SPDX from ADG data.

    Orchestrates AdgParser, ComponentResolver, and
    SpdxEmitter to produce one SPDX 2.3 JSON file per
    binary (e.g. curl, libcurl.so).
    """

    def __init__(
        self, bom_dir, repos_dir, repo_name,
        bomtrace_version="unknown",
        bomsh_version="unknown",
    ):
        self.bom_dir = Path(bom_dir)
        self.repos_dir = Path(repos_dir)
        self.repo_name = repo_name
        self.bomtrace_version = bomtrace_version
        self.bomsh_version = bomsh_version

    def generate(
        self, output_path,
        binary_name=None,
        dynlib_dir=None,
        direct_only=False,
    ):
        """Generate SPDX for a single binary.

        Args:
            output_path: where to write the SPDX JSON
            binary_name: name of the binary
                (e.g. "curl" or "libcurl.so");
                defaults to repo_name
            dynlib_dir: path to directory containing
                dynamic_libs.json for this binary;
                defaults to bom_dir/metadata
            direct_only: if True, include only direct
                dependencies. Use when transitive deps
                belong to a downstream binary's SBOM.

        Returns the output path on success, None on
        failure.
        """
        bin_name = binary_name or self.repo_name

        # Parse ADG for OmniBOR data
        parser = AdgParser(
            self.bom_dir, self.repos_dir
        )
        classified = parser.parse()
        doc_mapping = parser.load_doc_mapping()
        logfile_hashes = (
            parser.load_raw_logfile_hashes()
        )

        print(
            f"[{bin_name}] Source files: "
            f"{len(classified['project_source'])}, "
            f"Build intermediates: "
            f"{len(classified['build_intermediate'])}"
        )

        # Load component metadata
        meta_path = (
            self.bom_dir / "metadata"
            / "component_metadata.json"
        )
        if not meta_path.exists():
            print(
                "[ERROR] component_metadata.json "
                "not found. Run collect_metadata.py "
                "first."
            )
            return None

        resolver = ComponentResolver(str(meta_path))

        # Load dynamic library data
        dl_dir = Path(
            dynlib_dir
            if dynlib_dir
            else self.bom_dir / "metadata"
        )
        dynlib_path = dl_dir / "dynamic_libs.json"
        if not dynlib_path.exists():
            print(
                f"[ERROR] {dynlib_path} not found. "
                f"Run collect_dynamic_libs.py for "
                f"{bin_name} first."
            )
            return None

        resolver.load_dynamic_libs(
            str(dynlib_path)
        )
        components = (
            resolver.resolve_dynamic_components()
        )

        direct = sum(
            1 for c in components if c["direct"]
        )
        trans = len(components) - direct
        print(
            f"[{bin_name}] Dynamic libraries: "
            f"{len(components)} components "
            f"({direct} direct, "
            f"{trans} transitive)"
        )

        # Emit SPDX
        emitter = SpdxEmitter(
            repo_name=self.repo_name,
            repo_version=resolver.curl_version,
            distro=resolver.distro,
            gcc_version=resolver.gcc_version,
            bomtrace_version=self.bomtrace_version,
            bomsh_version=self.bomsh_version,
            binary_name=bin_name,
        )

        doc = emitter.emit(
            components=components,
            project_files=(
                classified["project_source"]
            ),
            doc_mapping=doc_mapping,
            logfile_hashes=logfile_hashes,
            direct_only=direct_only,
        )

        # Write output
        out = Path(output_path)
        out.parent.mkdir(parents=True, exist_ok=True)
        out.write_text(
            json.dumps(doc, indent=2) + "\n"
        )

        pkg_count = len(doc["packages"])
        file_count = len(doc["files"])
        rel_count = len(doc["relationships"])
        print(
            f"[OK] {bin_name} SPDX: {out.name} "
            f"({pkg_count} packages, "
            f"{file_count} files, "
            f"{rel_count} relationships)"
        )
        return str(out)


# ============================================================
# CLI
# ============================================================

def main():
    ap = argparse.ArgumentParser(
        description=(
            "Generate SPDX 2.3 from OmniBOR ADG data"
        ),
    )
    ap.add_argument(
        "--bom-dir", required=True,
        help="Path to OmniBOR output dir for repo",
    )
    ap.add_argument(
        "--repos-dir", required=True,
        help="Path to repos directory",
    )
    ap.add_argument(
        "--repo-name", required=True,
        help="Repository name (e.g. curl)",
    )
    ap.add_argument(
        "--output", required=True,
        help="Output SPDX JSON file path",
    )
    ap.add_argument(
        "--bomtrace-version", default="unknown",
    )
    ap.add_argument(
        "--bomsh-version", default="unknown",
    )
    ap.add_argument(
        "--binary-name", default=None,
        help=(
            "Binary name (e.g. curl, libcurl.so). "
            "Defaults to --repo-name"
        ),
    )
    ap.add_argument(
        "--dynlib-dir", default=None,
        help=(
            "Directory containing "
            "dynamic_libs.json for this binary"
        ),
    )
    ap.add_argument(
        "--direct-only",
        action="store_true",
        default=False,
        help=(
            "Include only direct dependencies. "
            "Use for two-tier SBOMs where "
            "transitive deps belong to a "
            "downstream binary's SBOM."
        ),
    )
    args = ap.parse_args()

    gen = AdgSpdxGenerator(
        bom_dir=args.bom_dir,
        repos_dir=args.repos_dir,
        repo_name=args.repo_name,
        bomtrace_version=args.bomtrace_version,
        bomsh_version=args.bomsh_version,
    )
    result = gen.generate(
        args.output,
        binary_name=args.binary_name,
        dynlib_dir=args.dynlib_dir,
        direct_only=args.direct_only,
    )
    if result:
        print(f"Success: {result}")
    else:
        print("Failed to generate SPDX")
        raise SystemExit(1)


if __name__ == "__main__":
    main()
